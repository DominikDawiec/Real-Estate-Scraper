{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b551059e-2e01-43dd-bee0-c70273d3269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the website that should be scraped \n",
    "website = 'https://www.morizon.pl/mieszkania/krakow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1c7876-4481-4912-9389-d3d0df2d3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading Selenium libraries \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# downloading BeautifulSoup library \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# downloading Numpy & Pandas libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# downloading additional libraries\n",
    "from requests import get\n",
    "import requests, openpyxl\n",
    "import re \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c620fa1-bd84-4208-9747-d7b538348617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Selenium options\n",
    "options = Options()\n",
    "options.add_argument(\"start-maximized\")\n",
    "\n",
    "# Start Chrome browser in the background\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e59312b-34dd-468d-baef-c42a143f1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HTML source of the website\n",
    "driver.get(website)\n",
    "html = driver.page_source\n",
    "\n",
    "# Replace tricky advertisement link with \"Unspecified\"\n",
    "html = html.replace(\"https://www.lendi.pl/formularz/kredyty-hipoteczne?hypothecValue=539900.00&loanPurpose.what=Apartment&loanPurpose.market=SecondaryMarket&meeting_voivoidship=małopolskie&meeting_city=Kraków&utm_entry_page=https://www.mori\", \"Unspecified\")\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the div containing the subcategories\n",
    "subcategories = soup.find(\"div\", {\"id\": \"locationListChildren\"})\n",
    "\n",
    "# Find the links to the subcategories\n",
    "links = []\n",
    "for link in subcategories.find_all(\"a\", href=re.compile(\"/mieszkania/\")):\n",
    "    links.append(link.get('href'))\n",
    "\n",
    "# Remove duplicated links\n",
    "links = list(dict.fromkeys(links))\n",
    "\n",
    "# Create full links by adding the base URL to each link\n",
    "base_url = \"https://www.morizon.pl\"\n",
    "full_links = [base_url + link for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73be10d4-7e38-4d57-81c7-b1a21a2cf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring_after(s, delim):\n",
    "   return s.partition(delim)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ecd5ebf-6cd2-4b2f-9fd0-2a30099859b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:40<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists\n",
    "pages = []\n",
    "pages2 = []\n",
    "\n",
    "# Initialize the progress bar\n",
    "pbar = tqdm(total=len(full_links))\n",
    "\n",
    "# Find the number of pages for each subcategory\n",
    "for link2 in full_links:\n",
    "    # Get the HTML source of the website\n",
    "    driver.get(link2)\n",
    "    html = driver.page_source\n",
    "    \n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Find the pagination elements\n",
    "    pagination = soup.find(\"ul\", {\"class\": \"nav nav-pills mz-pagination-number\"})\n",
    "    \n",
    "    # If pagination elements are found, find the maximum number of pages\n",
    "    if pagination:\n",
    "        flats = []\n",
    "        for link in pagination.find_all(\"a\", href=re.compile(\"/mieszkania/\")):\n",
    "            flat = link.get('href')\n",
    "            flat = substring_after(flat, \"page=\") \n",
    "            flats.append(flat)\n",
    "        flats2 = list(map(int, flats))\n",
    "        maxval = max(flats2)\n",
    "    else:\n",
    "        maxval = 1\n",
    "        \n",
    "    # Create the URL for each page\n",
    "    i = 0\n",
    "    for j in range(0, maxval):\n",
    "        i = i + 1\n",
    "        url = f\"{link2}?page={i}\"\n",
    "        pages2.append(url)\n",
    "    pages = pages2\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "    \n",
    "# Close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d94cdd-6c05-40fa-a450-bc090141193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [14:08<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the progress bar\n",
    "pbar = tqdm(total=len(pages))\n",
    "\n",
    "# Initialize empty list to store the links\n",
    "flats = []\n",
    "\n",
    "# Iterate over each page\n",
    "for page in pages:\n",
    "    # Get the HTML source of the website\n",
    "    driver.get(page)\n",
    "    html = driver.page_source\n",
    "    \n",
    "    # Replace advertisement link with \"Unspecified\"\n",
    "    html = html.replace(\"https://www.lendi.pl/formularz/kredyty-hipoteczne?hypothecValue=539900.00&loanPurpose.what=Apartment&loanPurpose.market=SecondaryMarket&meeting_voivoidship=małopolskie&meeting_city=Kraków&utm_entry_page=https://www.mori\",\"Unspecified\")\n",
    "    \n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Find the links and append them to the list\n",
    "    flats += [link.get('href') for link in soup.find_all(\"a\", href=re.compile(\"www.morizon.pl/oferta/sprzedaz-mieszkanie\"))]\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "    \n",
    "# Remove duplicated links\n",
    "flats = list(dict.fromkeys(flats))\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e991d1d-54a7-4d5f-a7c4-47ece7bd0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Excel workbook and a sheet\n",
    "excel = openpyxl.Workbook()\n",
    "sheet = excel.active\n",
    "\n",
    "# Change the sheet name\n",
    "sheet.title = 'Morizonflats'\n",
    "\n",
    "# Add rows that will be used as column names\n",
    "column_names = ['Total_Price', 'Price_per_Square_Meter', 'Total_living_area', 'Number_of_Rooms', 'Offer_Link', 'Latitude', 'Longitude', 'Developer_name', 'Walls_height', 'Investment_name', 'Floor', 'Total_number_of_floors', 'Kitchen_type', 'Number_of_bathrooms', 'Toilet_and_WC_type', 'Balcony', 'Total_area_of_Balcony', 'Total_area_of_Garden', 'Market_type', 'Available_from','Type_of_property', 'Type_of_Contract', 'Offer_ID', 'Date_of_last_update', 'Date_of_publication', 'Number_of_levels', 'Bedroom_area', 'Bathroom_area', 'Description']\n",
    "sheet.append(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fad053-675c-42ea-b587-2932c0decadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 5222/10729 [4:59:05<3:49:19,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n/a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10729/10729 [7:54:39<00:00,  2.65s/it] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(flats))\n",
    "\n",
    "for link in flats:\n",
    "    # Open the link to the flat\n",
    "    driver.get(link)\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Clean the HTML file for easier scraping\n",
    "    replacements = {\n",
    "        \"Cena\": \" \",\n",
    "        \"za m²\": \" \",\n",
    "        \"Powierzchnia\": \" \",\n",
    "        \"Pokoje\": \" \"\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        html = html.replace(old, new)\n",
    "        \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPrice'}):\n",
    "        price = soup.find('li', attrs={'class':'paramIconPrice'}).text.strip()\n",
    "        # cleaning price variable so it will only cointan numbers \n",
    "        price = price.replace(\"zł\",\" \")\n",
    "    else: price = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPriceM2'}):\n",
    "        pricem2 = soup.find('li', attrs={'class':'paramIconPriceM2'}).text.strip()\n",
    "        # cleaning price variable so it will only cointan numbers \n",
    "        pricem2 = pricem2.replace(\"zł\",\" \")\n",
    "    else: pricem2 = \"N/A\"\n",
    "        \n",
    "    # scraping price per sqm2\n",
    "    if soup.find('li', attrs={'class':'paramIconLivingArea'}):\n",
    "        livingarea = soup.find('li', attrs={'class':'paramIconLivingArea'}).text.strip()\n",
    "        # cleaning price variable so it will only cointan numbers \n",
    "        livingarea = livingarea.replace(\"m²\",\" \")\n",
    "    else: livingarea = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconNumberOfRooms'}):\n",
    "        rooms = soup.find('li', attrs={'class':'paramIconNumberOfRooms'}).text.strip()\n",
    "    else: rooms = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPrice'}):\n",
    "        price = soup.find('li', attrs={'class':'paramIconPrice'}).text.strip()\n",
    "    else: price = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPrice'}):\n",
    "        price = soup.find('li', attrs={'class':'paramIconPrice'}).text.strip()\n",
    "    else: price = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPrice'}):\n",
    "        price = soup.find('li', attrs={'class':'paramIconPrice'}).text.strip()\n",
    "    else: price = \"N/A\"\n",
    "        \n",
    "    # scraping price\n",
    "    if soup.find('li', attrs={'class':'paramIconPrice'}):\n",
    "        price = soup.find('li', attrs={'class':'paramIconPrice'}).text.strip()\n",
    "    else: price = \"N/A\"\n",
    "        \n",
    "    link2 = link\n",
    "    \n",
    "    # scraping description \n",
    "    description_element = soup.find(\"div\", {\"class\": \"description\"})\n",
    "    if description_element is not None:\n",
    "        if description_element.text.strip():\n",
    "            opis = description_element.text.strip()\n",
    "        else:\n",
    "            opis = \"N/A\"\n",
    "    else:\n",
    "        opis = \"N/A\"\n",
    "    \n",
    "    try:\n",
    "        lat = soup.find(\"div\", class_=\"GoogleMap\")[\"data-lat\"]\n",
    "    except:\n",
    "        lat = \"N/A\"\n",
    "        \n",
    "    try:\n",
    "        lng = soup.find(\"div\", class_=\"GoogleMap\")[\"data-lng\"]\n",
    "    except:\n",
    "        lng = \"N/A\"\n",
    "        \n",
    "    # scraping a table with additional informations  \n",
    "    div=soup.find_all('table')\n",
    "    \n",
    "    table0 = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        table0=pd.read_html(str(div[0]))\n",
    "\n",
    "        # transforming the table to string\n",
    "        ans = np.array(table0, dtype=\"object\")\n",
    "        ans = (ans[0])\n",
    "\n",
    "        # saving array as a dataframe \n",
    "        df = pd.DataFrame(ans)\n",
    "\n",
    "        df = df.rename(columns={0: \"a\", 1: \"b\"})\n",
    "\n",
    "        # pivoting table \n",
    "        table0 = pd.pivot_table(df, values='b', columns=['a'], aggfunc=np.sum)\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Deweloper:\" in table0.columns:\n",
    "            Deweloper = table0['Deweloper:'].iloc[0]\n",
    "        else: Deweloper = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Wysokość wnętrza:\" in table0.columns:\n",
    "            Wysokosc = table0['Wysokość wnętrza:'].iloc[0]\n",
    "        else: Wysokosc = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Inwestycja:\" in table0.columns:\n",
    "            Inwestycja = table0['Inwestycja:'].iloc[0]\n",
    "        else: Inwestycja = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Powierzchnia użytkowa:\" in table0.columns:\n",
    "            Powierzchnia = table0['Powierzchnia użytkowa:'].iloc[0]\n",
    "        else: Powierzchnia = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Piętro:\" in table0.columns:\n",
    "            Pietro = table0['Piętro:'].iloc[0]\n",
    "        else: Pietro = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Liczba pięter:\" in table0.columns:\n",
    "            Lpieter = table0['Liczba pięter:'].iloc[0]\n",
    "        else: Lpieter = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Typ kuchni:\" in table0.columns:\n",
    "            Kuchnia = table0['Typ kuchni:'].iloc[0]\n",
    "        else: Kuchnia = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Liczba łazienek:\" in table0.columns:\n",
    "            Lazienki = table0['Liczba łazienek:'].iloc[0]\n",
    "        else: Lazienki = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Czy łazienka z WC:\" in table0.columns:\n",
    "            LazWC = table0['Czy łazienka z WC:'].iloc[0]\n",
    "        else: LazWC = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Balkon:\" in table0.columns:\n",
    "            Balkon = table0['Balkon:'].iloc[0]\n",
    "        else: Balkon = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Powierzchnia balkonu:\" in table0.columns:\n",
    "            Powbalkonu = table0['Powierzchnia balkonu:'].iloc[0]\n",
    "        else: Powbalkonu = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Powierzchnia ogródka:\" in table0.columns:\n",
    "            PowOgrodka = table0['Powierzchnia ogródka:'].iloc[0]\n",
    "        else: PowOgrodka = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Rynek:\" in table0.columns:\n",
    "            Rynek = table0['Rynek:'].iloc[0]\n",
    "        else: Rynek = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Dostępne od:\" in table0.columns:\n",
    "            Dostod = table0['Dostępne od:'].iloc[0]\n",
    "        else: Dostod = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Forma własności:\" in table0.columns:\n",
    "            Formawlasnosci = table0['Forma własności:'].iloc[0]\n",
    "        else: Formawlasnosci = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Rodzaj umowy:\" in table0.columns:\n",
    "            RodzajUmowy = table0['Rodzaj umowy:'].iloc[0]\n",
    "        else: RodzajUmowy = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Numer oferty:\" in table0.columns:\n",
    "            NumOferty = table0['Numer oferty:'].iloc[0]\n",
    "        else: NumOferty = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Zaktualizowano:\" in table0.columns:\n",
    "            Zaktualizowano = table0['Zaktualizowano:'].iloc[0]\n",
    "        else: Zaktualizowano = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Opublikowano:\" in table0.columns:\n",
    "            Opublikowano = table0['Opublikowano:'].iloc[0]\n",
    "        else: Opublikowano = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Liczba poziomów mieszkania:\" in table0.columns:\n",
    "            PozMiesz = table0['Liczba poziomów mieszkania:'].iloc[0]\n",
    "        else: PozMiesz = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Liczba sypialni:\" in table0.columns:\n",
    "            Sypialn = table0['Liczba sypialni:'].iloc[0]\n",
    "        else: Sypialn = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Na biuro:\" in table0.columns:\n",
    "            Biur = table0['Na biuro:'].iloc[0]\n",
    "        else: Biur = \"N/A\"\n",
    "\n",
    "        # scraping information about developer (if applicable - else filling it with 'N/A')\n",
    "        if \"Powierzchnia łazienki:\" in table0.columns:\n",
    "            Lazienka = table0['Powierzchnia łazienki:'].iloc[0]\n",
    "        else: Lazienka = \"N/A\"\n",
    "        \n",
    "        # appending all scraped variables to an excel file \n",
    "        sheet.append([price, pricem2, livingarea, rooms, link2, lat, lng, Deweloper, Wysokosc, Inwestycja, Pietro, Lpieter, Kuchnia, Lazienki, LazWC, Balkon, Powbalkonu, PowOgrodka, Rynek, Dostod, Formawlasnosci, RodzajUmowy, NumOferty, Zaktualizowano, Opublikowano, PozMiesz, Sypialn, Lazienka, opis])\n",
    "    except:\n",
    "        print('n/a')\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# saving excel file \n",
    "excel.save('real_estate_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa4fe49-c875-4774-a91b-ae0ec8dd726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving excel file \n",
    "excel.save('real_estate_data2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70e600-3414-4c73-92a9-21decceb20fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
